{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4(reserv).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5oaY-svu21D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "!pip install --pre tensorflow-gpu==2.0.0a0\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "!pip install --upgrade --force-reinstall tb-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3kL4b2_I-Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "from tensorflow.keras import Model, datasets\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from datetime import datetime as ddt\n",
        "                                      \n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dG_fE7AD4nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/ \n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsvJ3SKEut_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(10000)\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).shuffle(10000)\n",
        "test_dataset = test_dataset.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmHR7T0Lu4OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ThreeConvs(Model):\n",
        "  def __init__(self):\n",
        "    super(ThreeConvs, self).__init__()\n",
        "    self.conv1 = Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))\n",
        "    self.pool1 = MaxPooling2D((2, 2))\n",
        "    self.conv2 = Conv2D(64, (3, 3), activation='relu')\n",
        "    self.pool2 = MaxPooling2D((2, 2))\n",
        "    self.conv3 = Conv2D(128, (3, 3), activation='relu')\n",
        "    self.flat = Flatten()\n",
        "    self.fc1 = Dense(512, activation='relu')\n",
        "    self.dropout = Dropout(0.5)\n",
        "    self.fc2 = Dense(10, activation='softmax')\n",
        "\n",
        "\n",
        "  def call(self, x, training = False):\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.fc1(x)\n",
        "    if training:\n",
        "        x = self.dropout(x)\n",
        "    return self.fc2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9w1-fEZI1St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sJ-xJelLe2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = ddt.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/lab4/' + current_time + '/train'\n",
        "test_log_dir = 'logs/lab4/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqqatS9lMZXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(image, label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(image)\n",
        "    loss = loss_object(label, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(label, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYscMgnEZGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(image, label):\n",
        "  predictions = model(image)\n",
        "  t_loss = loss_object(label, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(label, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyLDclanEbUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ThreeConvs() # reset model\n",
        "\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
        "\n",
        "EPOCHS = 8\n",
        "template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "template_step = 'Step {}, Loss: {}, Accuracy: {}'\n",
        "\n",
        "ckpt.restore(manager.latest_checkpoint)\n",
        "if manager.latest_checkpoint:\n",
        "  step_num = int(ckpt.step)\n",
        "  print(tf.train.list_variables('./tf_ckpts'))\n",
        "  print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "else:\n",
        "  step_num = 0\n",
        "  print(\"Initializing from scratch.\")\n",
        "\n",
        "%tensorboard --logdir logs/lab4\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  i = 0\n",
        "  for image, label in train_dataset:\n",
        "      train_step(image, label)\n",
        "      ckpt.step.assign_add(1)\n",
        "      with train_summary_writer.as_default():\n",
        "          tf.summary.scalar('loss', train_loss.result(), step=step_num)\n",
        "          tf.summary.scalar('accuracy', train_accuracy.result(), step=step_num)\n",
        "      if i % 100 == 0:\n",
        "          print(template_step.format(i+1, train_loss.result(), train_accuracy.result()*100))\n",
        "      step_num += 1\n",
        "      i += 1\n",
        "\n",
        "  for test_image, test_label in test_dataset:\n",
        "    test_step(test_image, test_label)\n",
        "  with test_summary_writer.as_default():\n",
        "      tf.summary.scalar('loss', test_loss.result(), step=step_num)\n",
        "      tf.summary.scalar('accuracy', test_accuracy.result(), step=step_num)\n",
        "\n",
        "  ckpt.mapped = {'step_num': step_num}\n",
        "  save_path = manager.save()\n",
        "  print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "  \n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "  # Reset metrics every epoch\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnyNvQg7EeTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./tf_ckpts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4VUtcOvpueZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}